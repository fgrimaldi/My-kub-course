# Exercise 7.3: Rolling Updates and Rollbacks



One of the advantages of micro services is the ability to replace and upgrade a container while continuing to respond to client requests. We will use the default OnDelete setting that upgrades a container when the predecessor is deleted, then the use the RollingUpdate feature as well.



Begin by viewing the current updateStrategy setting for the DaemonSet created in the previous section.



```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl get deploy taint -o yaml | grep -A 4 strategy
 strategy:
  rollingUpdate:
   maxSurge: 25%
   maxUnavailable: 25%
  type: RollingUpdate
```


[https://container-solutions.com/kubernetes-deployment-strategies/](https://container-solutions.com/kubernetes-deployment-strategies/)



```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl get ds daemonset1 -o yaml | grep -A 1 Strategy
 updateStrategy:
 type: OnDelete
```


Update the DaemonSet to use a newer version of the nginx server. This time use the set command instead of edit. Set the version to be 1.8.1-alpine.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl set image ds daemonset1 nginx=nginx:1.14-alpine
daemonset.extensions/daemonset1 image updated
```


Verify that the Image: parameter for the Pod checked in the previous section is unchanged.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl describe pod daemonset1-kq7pj | grep Image:
Image: nginx:1.7.9
```


Delete the Pod. Wait until the replacement Pod is running and check the version.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl delete po daemonset1-kq7pj
pod "daemonset1-kq7pj" deleted
```

```bash
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl get pod
NAME READY STATUS RESTARTS AGE
daemonset1-plbr7 1/1 Running 0 16m
daemonset1-tkzbg 1/1 Running 0 7s
```

```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl describe pod daemonset1-tkzbg | grep Image:
Image: nginx:1.14-alpine
```




View the image running on the older Pod. It should still show version 1.7.9.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl describe pod daemonset1-plbr7 | grep Image:
Image: nginx:1.7.9
```


View the history of changes for the DaemonSet. You should see two revisions listed. The number of revisions kept is set in the DaemonSet with v.1.12.1 the history kept has increased to ten from two, by default.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl rollout history ds daemonset1
daemonset.extensions/daemonset1
REVISION CHANGE-CAUSE
1 <none>
2 <none>
```


View the settings for the various versions of the DaemonSet. The Image: line should be the only difference between the two outputs.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl rollout history ds daemonset1 --revision=1
daemonset.extensions/daemonset1 with revision #1
Pod Template:
  Labels:  system=daemonset1
  Containers:
   nginx:
    Image:  nginx:1.7.9
    Port:  80/TCP
    Host Port:  0/TCP
    Environment:  <none>
    Mounts:  <none>
  Volumes:  <none>
```

```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl rollout history ds daemonset1 --revision=2  
....  
Image:  nginx:1.14-alpine  
....
```


Use kubectl rollout undo to change the DaemonSet back to an earlier version. As we are still using the OnDelete strategy there should be no change to the Pods.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl rollout undo ds daemonset1 --to-revision=1
daemonset.extensions/daemonset1 rolled back
```

```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl describe pod daemonset1-tkzbg | grep Image:
Image: nginx:1.14-alpine
```


Delete the Pod, wait for the replacement to spawn then check the image version again.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl delete pod daemonset1-tkzbg
pod "daemonset1-tkzbg" deleted
```

```bash
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl get pod
NAME READY STATUS RESTARTS AGE
daemonset1-gmfg6 1/1 Running 0 15s
daemonset1-plbr7 1/1 Running 0 26m
```

```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl describe pod daemonset1-gmfg6 | grep Image:
Image: nginx:1.7.9
```

```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl describe pod daemonset1-plbr7 | grep Image:
Image: nginx:1.7.9
```


View the details of the DaemonSet. The Image should be v1.7.9 in the output.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl describe ds |grep Image:
Image: nginx:1.7.9
```


View the current configuration for the DaemonSet in YAML output. Look for the update strategy near the end of the output.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl get ds daemonset1 -o yaml | grep -A 1 updateStrategy:
updateStrategy:
type: OnDelete
```


Create a new DaemonSet, this time setting the update policy to RollingUpdate. Begin by generating a new config file.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl get ds daemonset1 -o yaml --export > daemonset2.yaml
```


Edit the file. Change the name, around line eight and the update strategy around line 38.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ vim daemonset2.yaml  
....  
name: daemonset2  
....  
type: RollingUpdate
```


Create the new DaemonSet and verify the nginx version in the new pods.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl create -f daemonset2.yaml
kubedaemonset.extensions/daemonset2 created
```



```bash
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl get pod
NAME READY STATUS RESTARTS AGE
daemonset1-gmfg6 1/1 Running 0 11m
daemonset1-plbr7 1/1 Running 0 37m
daemonset2-9s69p 1/1 Running 0 3s
daemonset2-lwqn7 1/1 Running 0 3s
```

```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl describe pod daemonset2-9s69p | grep Image:
Image: nginx:1.7.9
```


Edit the configuration file and set the image to a newer version such as 1.14-alpine.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl edit ds daemonset2

....  
    spec:
      containers:
      - image: nginx:1.14-alpine #<<<---- Change this line
        imagePullPolicy: IfNotPresent  
.....

daemonset.extensions/daemonset2 edited
```




View the age of the DaemonSets. It should be around ten minutes old, depending on how fast you type.


```bash
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl get ds daemonset2
NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE
daemonset2 2 2 2 2 2 <none> 2m34s
```


Now view the age of the Pods. Two should be much younger than the DaemonSet. They are also a few seconds apart due to the nature of the rolling update where one then the other pod was terminated and recreated.


```bash
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl get pod
NAME READY STATUS RESTARTS AGE
daemonset1-gmfg6 1/1 Running 0 14m
daemonset1-plbr7 1/1 Running 0 40m
daemonset2-kk9dw 1/1 Running 0 71s
daemonset2-pms59 1/1 Running 0 62s
```


Verify the Pods are using the new version of the software.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl describe pod daemonset2-kk9dw | grep Image:  
Image: nginx:1.14-alpine  
```
```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl describe pod daemonset2-pms59 | grep Image:  
Image: nginx:1.14-alpine
```



View the rollout status and the history of the DaemonSets.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl rollout status ds daemonset2
daemon set "daemonset2" successfully rolled out
```



```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl rollout history ds daemonset2

daemonset.extensions/daemonset2

REVISION CHANGE-CAUSE

1 <none>

2 <none>
```


View the changes in the update they should look the same as the previous history, but did not require the Pods to be deleted for the update to take place.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl rollout history ds daemonset2 --revision=2
daemonset.extensions/daemonset2 with revision #2
Pod Template:
  Labels:  system=daemonset1
  Containers:
   nginx:
    Image:  nginx:1.14-alpine
    Port:  80/TCP
    Host Port:  0/TCP
    Environment:  <none>
    Mounts:  <none>
  Volumes:  <none>
```


Clean up the system by removing one of the DaemonSets. We will leave the other running.


```
[student@controller01 ~ (⎈ |kubernetes-admin@kubernetes:default)]$ kubectl delete ds daemonset2
daemonset.extensions "daemonset2" deleted
```

$ kubectl rolling-update frontend-v1 -f frontend-v2.json           # Rolling update pods of frontend-v1
$ kubectl rolling-update frontend-v1 frontend-v2 --image=image:v2  # Change the name of the resource and update the image
$ kubectl rolling-update frontend --image=image:v2                 # Update the pods image of frontend
$ kubectl rolling-update frontend-v1 frontend-v2 --rollback        # Abort existing rollout in progress
$ cat pod.json | kubectl replace -f -                              # Replace a pod based on the JSON passed into stdin

# Force replace, delete and then re-create the resource. Will cause a service outage.
$ kubectl replace --force -f ./pod.json

# Create a service for a replicated nginx, which serves on port 80 and connects to the containers on port 8000
$ kubectl expose rc nginx --port=80 --target-port=8000

# Update a single-container pod's image version (tag) to v4
$ kubectl get pod mypod -o yaml | sed 's/\(image: myimage\):.*$/\1:v4/' | kubectl replace -f -

$ kubectl label pods my-pod new-label=awesome                      # Add a Label
$ kubectl annotate pods my-pod icon-url=http://goo.gl/XXBTWq       # Add an annotation
$ kubectl autoscale deployment foo --min=2 --max=10                # Auto scale a deployment "foo"



[Back](lab07.md)
